{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bcdad587af7f41a1b94ee13b8d019e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ebd633e1c064710852b05e8d77ba119",
              "IPY_MODEL_d82fcfef3e86408784a408b05c4b4208",
              "IPY_MODEL_c4e96424b22d473b9c8e96b2d0436f12"
            ],
            "layout": "IPY_MODEL_70ba414689ff475daa652b93d66cf366"
          }
        },
        "2ebd633e1c064710852b05e8d77ba119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_479a23f6d816402a9d210b7eb7a2b9f8",
            "placeholder": "​",
            "style": "IPY_MODEL_ada66373c8ee472baec2fd86c4ca70ce",
            "value": "tokenizer_config.json: "
          }
        },
        "d82fcfef3e86408784a408b05c4b4208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61f2cf992d844bc9a27ca1b6c560f671",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22519a09c5164250a7f0ae8d77d3e662",
            "value": 1
          }
        },
        "c4e96424b22d473b9c8e96b2d0436f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfe29e1c952c4214bdbeb49b41466e2f",
            "placeholder": "​",
            "style": "IPY_MODEL_a6b03b123e994b2095a60586b8c4c5dc",
            "value": " 7.32k/? [00:00&lt;00:00, 538kB/s]"
          }
        },
        "70ba414689ff475daa652b93d66cf366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "479a23f6d816402a9d210b7eb7a2b9f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ada66373c8ee472baec2fd86c4ca70ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61f2cf992d844bc9a27ca1b6c560f671": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "22519a09c5164250a7f0ae8d77d3e662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfe29e1c952c4214bdbeb49b41466e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b03b123e994b2095a60586b8c4c5dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e63751e2fbd54029af5cc1a717bc7d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02afb8edf8cf443286b2547343e51197",
              "IPY_MODEL_2dd1801068e74232a8423de22e24525e",
              "IPY_MODEL_13ab53e2e02445f5924097a76198355a"
            ],
            "layout": "IPY_MODEL_62ce4c4a032f43cfa013a772da41b3a0"
          }
        },
        "02afb8edf8cf443286b2547343e51197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feeb16aed27e4511a8a34916b0dc0c99",
            "placeholder": "​",
            "style": "IPY_MODEL_785cb685de6b4cd793a1f62354155e00",
            "value": "vocab.json: "
          }
        },
        "2dd1801068e74232a8423de22e24525e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_002335aa8a6c4d92a3013f2eb5231712",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09e941fdde27416d8793e8c21acd7cb3",
            "value": 1
          }
        },
        "13ab53e2e02445f5924097a76198355a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dea79fba8b0452c9d6099461a3b7137",
            "placeholder": "​",
            "style": "IPY_MODEL_525fa17f4b944472a69dac4c0644f14f",
            "value": " 2.78M/? [00:00&lt;00:00, 33.8MB/s]"
          }
        },
        "62ce4c4a032f43cfa013a772da41b3a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feeb16aed27e4511a8a34916b0dc0c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "785cb685de6b4cd793a1f62354155e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "002335aa8a6c4d92a3013f2eb5231712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "09e941fdde27416d8793e8c21acd7cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9dea79fba8b0452c9d6099461a3b7137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "525fa17f4b944472a69dac4c0644f14f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70200a80180f40fab25e94227c735067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c94028e4fd1647afbe9a5efcf0526df8",
              "IPY_MODEL_adc8fdeee8994fcebbca49bb4564c427",
              "IPY_MODEL_34dce480bb87420a955fcc63bfe788d7"
            ],
            "layout": "IPY_MODEL_966de7633d8744e2a683578adf189b33"
          }
        },
        "c94028e4fd1647afbe9a5efcf0526df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91d979b2102e499aacfd37e67b345776",
            "placeholder": "​",
            "style": "IPY_MODEL_d2023c069dbc4522ab2f40058fe48c87",
            "value": "merges.txt: "
          }
        },
        "adc8fdeee8994fcebbca49bb4564c427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7f904f94de948f9ae261fe20f14d193",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_461548bd6dcd4a4d955b2a8277d86a75",
            "value": 1
          }
        },
        "34dce480bb87420a955fcc63bfe788d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dee89a7665b94e3a9e2291821e778b6a",
            "placeholder": "​",
            "style": "IPY_MODEL_38157d8398c047f381f933206d326bfe",
            "value": " 1.67M/? [00:00&lt;00:00, 45.2MB/s]"
          }
        },
        "966de7633d8744e2a683578adf189b33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d979b2102e499aacfd37e67b345776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2023c069dbc4522ab2f40058fe48c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7f904f94de948f9ae261fe20f14d193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "461548bd6dcd4a4d955b2a8277d86a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dee89a7665b94e3a9e2291821e778b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38157d8398c047f381f933206d326bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7305de2ed5f45dc9cb09ac2062cf7bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e02918efaed45388050e4518967734e",
              "IPY_MODEL_347582b568f54895bcd2b125874da2ec",
              "IPY_MODEL_cac9f3e9ff434a4692ccb382700fe102"
            ],
            "layout": "IPY_MODEL_3dc3cdc65e9d441c90772eb18da1dcdc"
          }
        },
        "8e02918efaed45388050e4518967734e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5777561ddc8b4ce5959fd040bfab1200",
            "placeholder": "​",
            "style": "IPY_MODEL_d069087803cf4694ae13aeb0bd8723dc",
            "value": "tokenizer.json: "
          }
        },
        "347582b568f54895bcd2b125874da2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3bbb37db35146de98a6fec1ed5ef87d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8cfb2c830c5945219c9567971077c254",
            "value": 1
          }
        },
        "cac9f3e9ff434a4692ccb382700fe102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20fc97ec78ae433e9d3b226d242e1149",
            "placeholder": "​",
            "style": "IPY_MODEL_c6db70679dd24c6c905c6a56ce4fa38b",
            "value": " 7.03M/? [00:00&lt;00:00, 102MB/s]"
          }
        },
        "3dc3cdc65e9d441c90772eb18da1dcdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5777561ddc8b4ce5959fd040bfab1200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d069087803cf4694ae13aeb0bd8723dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3bbb37db35146de98a6fec1ed5ef87d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8cfb2c830c5945219c9567971077c254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20fc97ec78ae433e9d3b226d242e1149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6db70679dd24c6c905c6a56ce4fa38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b2847e379704b6d92496e9905dc13b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe0c9d33a0fd4d8198dab72bb8837ea2",
              "IPY_MODEL_86b19b4f9910488288ce734413f5a2a0",
              "IPY_MODEL_04c2a7c54c9d4ac89f86251a3f41cb6e"
            ],
            "layout": "IPY_MODEL_daabe6b73d27498fb79a4c48af377301"
          }
        },
        "fe0c9d33a0fd4d8198dab72bb8837ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18ee38086875460db2a8a109b83495c6",
            "placeholder": "​",
            "style": "IPY_MODEL_7a3e4606057448fa89f16fd298b485f4",
            "value": "config.json: 100%"
          }
        },
        "86b19b4f9910488288ce734413f5a2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f0eab5072f94c599dccb526a985cc9e",
            "max": 676,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_802013cced7b48bb8c0b005ecea27552",
            "value": 676
          }
        },
        "04c2a7c54c9d4ac89f86251a3f41cb6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d49fa6ff4c2f453fa82842b98221685e",
            "placeholder": "​",
            "style": "IPY_MODEL_62a2fc85043647c0b686ebf1d6829c64",
            "value": " 676/676 [00:00&lt;00:00, 40.1kB/s]"
          }
        },
        "daabe6b73d27498fb79a4c48af377301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ee38086875460db2a8a109b83495c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a3e4606057448fa89f16fd298b485f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f0eab5072f94c599dccb526a985cc9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "802013cced7b48bb8c0b005ecea27552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d49fa6ff4c2f453fa82842b98221685e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62a2fc85043647c0b686ebf1d6829c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa0e2d6623244ed7b8b1597d43556127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d93cde2d914a4888ba5ed570fac19e98",
              "IPY_MODEL_60974462b584438fb4e5a985ab38b317",
              "IPY_MODEL_5a8402b6550f467eb5086d0a9a97de4f"
            ],
            "layout": "IPY_MODEL_4d44bb69ae6f447ab60059d5fa91b23b"
          }
        },
        "d93cde2d914a4888ba5ed570fac19e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b41cf3231c3418eb33f9895b1876525",
            "placeholder": "​",
            "style": "IPY_MODEL_90e111d59af2421daf31664a5e1c4318",
            "value": "model.safetensors: 100%"
          }
        },
        "60974462b584438fb4e5a985ab38b317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a72852e1f1aa48c3a5fd02d6856b43cf",
            "max": 3087467144,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1c79c87801b48b7b6586bdb25e2d111",
            "value": 3087467144
          }
        },
        "5a8402b6550f467eb5086d0a9a97de4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_132238f8912d4492acb5918e2b6183dd",
            "placeholder": "​",
            "style": "IPY_MODEL_c459a423bbb140be8930f7c3614d12cc",
            "value": " 3.09G/3.09G [01:15&lt;00:00, 58.8MB/s]"
          }
        },
        "4d44bb69ae6f447ab60059d5fa91b23b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b41cf3231c3418eb33f9895b1876525": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90e111d59af2421daf31664a5e1c4318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a72852e1f1aa48c3a5fd02d6856b43cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c79c87801b48b7b6586bdb25e2d111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "132238f8912d4492acb5918e2b6183dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c459a423bbb140be8930f7c3614d12cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70c2d17d668b41fb9cf8e0cddae98f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1df21d8e800d4328b2dde9a556e375e8",
              "IPY_MODEL_da8a055517384c9cb7a33a1f221e956f",
              "IPY_MODEL_2107a6c740964224892f68fc4f94b02d"
            ],
            "layout": "IPY_MODEL_d25b73b4bad74c5ea7d32589d3330212"
          }
        },
        "1df21d8e800d4328b2dde9a556e375e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71c699b10ba2466fbcd9ffdd07cd15df",
            "placeholder": "​",
            "style": "IPY_MODEL_76707b7ea87a421390bbdc96c4d493af",
            "value": "generation_config.json: 100%"
          }
        },
        "da8a055517384c9cb7a33a1f221e956f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5df48ef8d434b9e93ccfbf42048a552",
            "max": 138,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6d8881e778c48748b3e00551fbc615b",
            "value": 138
          }
        },
        "2107a6c740964224892f68fc4f94b02d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_010a41db367141c8b32a7fb548ca8f73",
            "placeholder": "​",
            "style": "IPY_MODEL_865d4827638d4cb99fa9511b49259285",
            "value": " 138/138 [00:00&lt;00:00, 14.3kB/s]"
          }
        },
        "d25b73b4bad74c5ea7d32589d3330212": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71c699b10ba2466fbcd9ffdd07cd15df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76707b7ea87a421390bbdc96c4d493af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5df48ef8d434b9e93ccfbf42048a552": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6d8881e778c48748b3e00551fbc615b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "010a41db367141c8b32a7fb548ca8f73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "865d4827638d4cb99fa9511b49259285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hu3-Ge1um2K3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from torch.cuda.amp import autocast, GradScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "# Device setup\n",
        "# 'accelerate' with device_map='auto' will handle device placement.\n",
        "# We still might need this for moving specific tensors like rewards or inputs.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6The554nOhm",
        "outputId": "4e0d3616-7d4f-4869-87e5-a3786dc7d05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Memory Optimization Settings ---\n",
        "# No need to call torch.cuda.empty_cache() at the start\n",
        "# torch.backends.cuda.enable_mem_efficient_sdp(False) # Keep commented unless needed for specific issues\n",
        "\n",
        "# --- Model and Tokenizer Loading ---\n",
        "model_name = \"Qwen/Qwen2.5-Math-1.5B\"\n",
        "print(f\"Loading tokenizer: {model_name}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286,
          "referenced_widgets": [
            "bcdad587af7f41a1b94ee13b8d019e11",
            "2ebd633e1c064710852b05e8d77ba119",
            "d82fcfef3e86408784a408b05c4b4208",
            "c4e96424b22d473b9c8e96b2d0436f12",
            "70ba414689ff475daa652b93d66cf366",
            "479a23f6d816402a9d210b7eb7a2b9f8",
            "ada66373c8ee472baec2fd86c4ca70ce",
            "61f2cf992d844bc9a27ca1b6c560f671",
            "22519a09c5164250a7f0ae8d77d3e662",
            "cfe29e1c952c4214bdbeb49b41466e2f",
            "a6b03b123e994b2095a60586b8c4c5dc",
            "e63751e2fbd54029af5cc1a717bc7d9e",
            "02afb8edf8cf443286b2547343e51197",
            "2dd1801068e74232a8423de22e24525e",
            "13ab53e2e02445f5924097a76198355a",
            "62ce4c4a032f43cfa013a772da41b3a0",
            "feeb16aed27e4511a8a34916b0dc0c99",
            "785cb685de6b4cd793a1f62354155e00",
            "002335aa8a6c4d92a3013f2eb5231712",
            "09e941fdde27416d8793e8c21acd7cb3",
            "9dea79fba8b0452c9d6099461a3b7137",
            "525fa17f4b944472a69dac4c0644f14f",
            "70200a80180f40fab25e94227c735067",
            "c94028e4fd1647afbe9a5efcf0526df8",
            "adc8fdeee8994fcebbca49bb4564c427",
            "34dce480bb87420a955fcc63bfe788d7",
            "966de7633d8744e2a683578adf189b33",
            "91d979b2102e499aacfd37e67b345776",
            "d2023c069dbc4522ab2f40058fe48c87",
            "f7f904f94de948f9ae261fe20f14d193",
            "461548bd6dcd4a4d955b2a8277d86a75",
            "dee89a7665b94e3a9e2291821e778b6a",
            "38157d8398c047f381f933206d326bfe",
            "d7305de2ed5f45dc9cb09ac2062cf7bc",
            "8e02918efaed45388050e4518967734e",
            "347582b568f54895bcd2b125874da2ec",
            "cac9f3e9ff434a4692ccb382700fe102",
            "3dc3cdc65e9d441c90772eb18da1dcdc",
            "5777561ddc8b4ce5959fd040bfab1200",
            "d069087803cf4694ae13aeb0bd8723dc",
            "c3bbb37db35146de98a6fec1ed5ef87d",
            "8cfb2c830c5945219c9567971077c254",
            "20fc97ec78ae433e9d3b226d242e1149",
            "c6db70679dd24c6c905c6a56ce4fa38b"
          ]
        },
        "id": "CZ23DQ-0nV2V",
        "outputId": "5e735eac-1fd4-4405-a560-0a071f7f3510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tokenizer: Qwen/Qwen2.5-Math-1.5B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcdad587af7f41a1b94ee13b8d019e11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e63751e2fbd54029af5cc1a717bc7d9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70200a80180f40fab25e94227c735067"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7305de2ed5f45dc9cb09ac2062cf7bc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set pad token if it doesn't exist\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    print(\"Set tokenizer pad_token to eos_token\")\n",
        "\n",
        "print(f\"Loading model: {model_name}\")\n",
        "# Load the main model with device_map='auto', gradient checkpointing, and float16\n",
        "# device_map='auto' handles placing the model on available GPUs/CPU/disk\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\", # Let accelerate handle device placement\n",
        "    torch_dtype=torch.float16,\n",
        "    trust_remote_code=True # Add if required by the specific model\n",
        ")\n",
        "model.gradient_checkpointing_enable() # Enable gradient checkpointing *after* loading\n",
        "# DO NOT call model.to(device) here - device_map handles it.\n",
        "print(\"Model loaded onto devices via device_map='auto'\")\n",
        "\n",
        "print(\"Loading reference model...\")\n",
        "# Load the reference model similarly\n",
        "reference_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\", # Let accelerate handle device placement\n",
        "    torch_dtype=torch.float16,\n",
        "    trust_remote_code=True # Add if required by the specific model\n",
        ")\n",
        "reference_model.eval() # Set reference model to evaluation mode\n",
        "# DO NOT call reference_model.to(device) here - device_map handles it.\n",
        "print(\"Reference model loaded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "2b2847e379704b6d92496e9905dc13b0",
            "fe0c9d33a0fd4d8198dab72bb8837ea2",
            "86b19b4f9910488288ce734413f5a2a0",
            "04c2a7c54c9d4ac89f86251a3f41cb6e",
            "daabe6b73d27498fb79a4c48af377301",
            "18ee38086875460db2a8a109b83495c6",
            "7a3e4606057448fa89f16fd298b485f4",
            "5f0eab5072f94c599dccb526a985cc9e",
            "802013cced7b48bb8c0b005ecea27552",
            "d49fa6ff4c2f453fa82842b98221685e",
            "62a2fc85043647c0b686ebf1d6829c64",
            "aa0e2d6623244ed7b8b1597d43556127",
            "d93cde2d914a4888ba5ed570fac19e98",
            "60974462b584438fb4e5a985ab38b317",
            "5a8402b6550f467eb5086d0a9a97de4f",
            "4d44bb69ae6f447ab60059d5fa91b23b",
            "7b41cf3231c3418eb33f9895b1876525",
            "90e111d59af2421daf31664a5e1c4318",
            "a72852e1f1aa48c3a5fd02d6856b43cf",
            "a1c79c87801b48b7b6586bdb25e2d111",
            "132238f8912d4492acb5918e2b6183dd",
            "c459a423bbb140be8930f7c3614d12cc",
            "70c2d17d668b41fb9cf8e0cddae98f5a",
            "1df21d8e800d4328b2dde9a556e375e8",
            "da8a055517384c9cb7a33a1f221e956f",
            "2107a6c740964224892f68fc4f94b02d",
            "d25b73b4bad74c5ea7d32589d3330212",
            "71c699b10ba2466fbcd9ffdd07cd15df",
            "76707b7ea87a421390bbdc96c4d493af",
            "d5df48ef8d434b9e93ccfbf42048a552",
            "c6d8881e778c48748b3e00551fbc615b",
            "010a41db367141c8b32a7fb548ca8f73",
            "865d4827638d4cb99fa9511b49259285"
          ]
        },
        "id": "69OSiALznfmE",
        "outputId": "5f438d19-f044-46a8-93bb-eea384fbd3bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: Qwen/Qwen2.5-Math-1.5B\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/676 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b2847e379704b6d92496e9905dc13b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa0e2d6623244ed7b8b1597d43556127"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70c2d17d668b41fb9cf8e0cddae98f5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded onto devices via device_map='auto'\n",
            "Loading reference model...\n",
            "Reference model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example Data ---\n",
        "example = {\n",
        "    \"prompt\": \"The pressure \\\\( P \\\\) exerted by wind on a sail varies jointly as the area \\\\( A \\\\) of the sail and the cube of the wind’s velocity \\\\( V \\\\). When the velocity is \\\\( 8 \\\\) miles per hour, the pressure on a sail of \\\\( 2 \\\\) square feet is \\\\( 4 \\\\) pounds. Find the wind velocity when the pressure on \\\\( 4 \\\\) square feet of sail is \\\\( 32 \\\\) pounds. Let’s think step by step and output the final answer within \\\\boxed{}.\",\n",
        "    # Previous attempt at recalculating GT removed to fix syntax error.\n",
        "    # Using the user's original GT string for consistency with the initial request.\n",
        "    \"ground_truth\": \"12.8\"\n",
        "}\n",
        "\n",
        "# --- Dataset Preparation ---\n",
        "# Reduced batch size for memory, effective batch size simulated with accumulation\n",
        "batch_size = 4 # Significantly reduced for memory\n",
        "effective_batch_size = 32 # Target effective batch size\n",
        "accumulation_steps = max(1, effective_batch_size // batch_size) # Calculate accumulation steps\n",
        "print(f\"Physical Batch Size: {batch_size}, Accumulation Steps: {accumulation_steps}, Effective Batch Size: {batch_size * accumulation_steps}\")\n",
        "\n",
        "# Duplicate the single example to create a batch\n",
        "data = [example] * (batch_size * accumulation_steps) # Create enough data for one effective batch\n",
        "dataset = Dataset.from_dict({\n",
        "    \"prompt\": [d[\"prompt\"] for d in data],\n",
        "    \"ground_truth\": [d[\"ground_truth\"] for d in data]\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErpxII6_oDq3",
        "outputId": "f01be829-b17d-425b-c3a3-8b60ab0cdc36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physical Batch Size: 4, Accumulation Steps: 8, Effective Batch Size: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Hyperparameters ---\n",
        "learning_rate = 1e-6\n",
        "kl_coeff = 0.02 # Adjusted KL coefficient, often needs tuning\n",
        "entropy_coeff = 0.001 # Entropy bonus to encourage exploration\n",
        "rollout_temperature = 0.7 # Temperature for sampling responses\n",
        "weight_decay = 0.01\n",
        "max_prompt_length = 512 # Max length for input prompt tokens\n",
        "# Adjust max_response_length based on expected output length and memory\n",
        "# max_new_tokens will be max_total_length - prompt_length\n",
        "max_total_length = 768 # Reduced total length (prompt + response)\n",
        "num_steps = 200 # Reduced number of steps for quicker testing\n",
        "samples_per_prompt = 2 # Reduced samples per prompt for memory\n"
      ],
      "metadata": {
        "id": "ZttErWBRoS8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Optimizer and Scaler ---\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "scaler = GradScaler() # For mixed precision\n",
        "\n",
        "# --- Reward Function ---\n",
        "def compute_reward(response, ground_truth):\n",
        "    \"\"\"Binary reward: 1.0 if ground_truth is in response, 0.0 otherwise.\"\"\"\n",
        "    # Simple check, might need more sophisticated reward logic (e.g., parsing the boxed answer)\n",
        "    # Check if the exact ground_truth string is present in the response.\n",
        "    # A more robust check might involve parsing \"\\\\boxed{...}\"\n",
        "    return 1.0 if ground_truth in response else 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riXijg5xoXlJ",
        "outputId": "0815c785-fe8a-4c40-b278-8610ae676d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3922865737.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # For mixed precision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_grpo_loss(policy_logits, policy_sampled_ids, policy_attention_mask,\n",
        "                      ref_log_probs_generated, rewards, kl_coeff, entropy_coeff,\n",
        "                      pad_token_id, prompt_length):\n",
        "    \"\"\"\n",
        "    Memory-efficient GRPO loss computation (without entropy to save memory).\n",
        "\n",
        "    Args:\n",
        "        policy_logits: Logits from the policy model for generated tokens. Shape (B*S, GenLen, V)\n",
        "        policy_sampled_ids: Full sequence IDs (prompt + generated). Shape (B*S, FullLen)\n",
        "        policy_attention_mask: Attention mask for the full sequence. Shape (B*S, FullLen)\n",
        "        ref_log_probs_generated: Log probabilities from reference model for generated tokens. Shape (B*S, GenLen)\n",
        "        rewards: List of scalar rewards for each sampled sequence.\n",
        "        kl_coeff: Coefficient for KL divergence term.\n",
        "        entropy_coeff: Coefficient for entropy bonus term (unused, kept for compatibility).\n",
        "        pad_token_id: ID of the padding token.\n",
        "        prompt_length: Length of the initial prompt sequence.\n",
        "\n",
        "    Returns:\n",
        "        Total loss tensor.\n",
        "        Tuple containing (pg_loss, kl_loss, entropy_loss) for logging.\n",
        "    \"\"\"\n",
        "    B_times_S = policy_logits.shape[0]\n",
        "    gen_len = policy_logits.shape[1]\n",
        "\n",
        "    # Extract generated tokens only\n",
        "    generated_ids = policy_sampled_ids[:, prompt_length:]  # (B*S, GenLen)\n",
        "    gen_attention_mask = policy_attention_mask[:, prompt_length:].float()  # (B*S, GenLen)\n",
        "\n",
        "    # Compute policy log probs efficiently\n",
        "    policy_log_probs = F.log_softmax(policy_logits, dim=-1)  # (B*S, GenLen, V)\n",
        "    policy_log_probs_sampled = torch.gather(\n",
        "        policy_log_probs,\n",
        "        dim=-1,\n",
        "        index=generated_ids.unsqueeze(-1)\n",
        "    ).squeeze(-1)  # (B*S, GenLen)\n",
        "\n",
        "    # Clean up immediately to save memory\n",
        "    del policy_log_probs\n",
        "\n",
        "    # --- 1. Policy Gradient Loss (REINFORCE) ---\n",
        "    rewards_tensor = torch.tensor(rewards, device=policy_logits.device, dtype=policy_logits.dtype)\n",
        "\n",
        "    # Normalize rewards\n",
        "    if len(rewards) > 1:\n",
        "        rewards_mean = rewards_tensor.mean()\n",
        "        rewards_std = rewards_tensor.std() + 1e-8\n",
        "        normalized_rewards = (rewards_tensor - rewards_mean) / rewards_std\n",
        "    else:\n",
        "        normalized_rewards = rewards_tensor\n",
        "\n",
        "    # Expand rewards to token level\n",
        "    normalized_rewards_expanded = normalized_rewards.view(-1, 1)  # (B*S, 1)\n",
        "\n",
        "    # Policy gradient: -log_prob * advantage (negative because we minimize)\n",
        "    pg_loss_per_token = -policy_log_probs_sampled * normalized_rewards_expanded  # (B*S, GenLen)\n",
        "    pg_loss = (pg_loss_per_token * gen_attention_mask).sum() / gen_attention_mask.sum().clamp(min=1)\n",
        "\n",
        "    # --- 2. KL Divergence Penalty ---\n",
        "    # KL(π || ref) = log π(a|s) - log ref(a|s)\n",
        "    kl_per_token = policy_log_probs_sampled - ref_log_probs_generated  # (B*S, GenLen)\n",
        "    mean_kl = (kl_per_token * gen_attention_mask).sum() / gen_attention_mask.sum().clamp(min=1)\n",
        "    kl_penalty = kl_coeff * mean_kl\n",
        "\n",
        "    # --- 3. Entropy (set to 0 to save memory) ---\n",
        "    # The entropy calculation causes OOM, so we skip it\n",
        "    entropy_loss = torch.tensor(0.0, device=policy_logits.device)\n",
        "\n",
        "    # --- Total Loss ---\n",
        "    total_loss = pg_loss + kl_penalty + entropy_loss\n",
        "\n",
        "    return total_loss, (pg_loss.item(), kl_penalty.item(), entropy_loss.item())"
      ],
      "metadata": {
        "id": "5nDdKHMJqkzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "from contextlib import nullcontext\n",
        "\n",
        "# ===== SETUP AND CONFIGURATION =====\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Enable gradient checkpointing\n",
        "if hasattr(model, 'gradient_checkpointing_enable'):\n",
        "    model.gradient_checkpointing_enable()\n",
        "\n",
        "# Memory management\n",
        "def clear_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "    gc.collect()\n",
        "\n",
        "# ===== SAFE LOSS FUNCTION =====\n",
        "def safe_compute_grpo_loss(policy_logits, policy_sampled_ids, policy_attention_mask,\n",
        "                          ref_log_probs_generated, rewards, kl_coeff, entropy_coeff,\n",
        "                          pad_token_id, prompt_length):\n",
        "    \"\"\"\n",
        "    Safe version that handles tensor size mismatches\n",
        "    \"\"\"\n",
        "    # Extract generated tokens\n",
        "    generated_ids = policy_sampled_ids[:, prompt_length:]\n",
        "    generated_mask = policy_attention_mask[:, prompt_length:]\n",
        "    gen_length = generated_ids.shape[1]\n",
        "\n",
        "    # Ensure all tensors have the same sequence length\n",
        "    min_length = min(policy_logits.shape[1], ref_log_probs_generated.shape[1], gen_length)\n",
        "\n",
        "    if min_length < gen_length:\n",
        "        print(f\"    WARNING: Truncating sequences from {gen_length} to {min_length}\")\n",
        "        generated_ids = generated_ids[:, :min_length]\n",
        "        generated_mask = generated_mask[:, :min_length]\n",
        "        policy_logits = policy_logits[:, :min_length, :]\n",
        "        ref_log_probs_generated = ref_log_probs_generated[:, :min_length]\n",
        "        gen_length = min_length\n",
        "\n",
        "    # Calculate policy log probs\n",
        "    policy_log_probs = F.log_softmax(policy_logits, dim=-1)\n",
        "    policy_log_probs_sampled = torch.gather(\n",
        "        policy_log_probs, -1, generated_ids.unsqueeze(-1)\n",
        "    ).squeeze(-1)\n",
        "\n",
        "    # Calculate KL divergence\n",
        "    kl_div = policy_log_probs_sampled - ref_log_probs_generated\n",
        "    kl_div = kl_div * generated_mask  # Mask out padding\n",
        "\n",
        "    # Calculate entropy\n",
        "    entropy = -torch.sum(\n",
        "        torch.exp(policy_log_probs) * policy_log_probs * generated_mask.unsqueeze(-1),\n",
        "        dim=-1\n",
        "    )\n",
        "\n",
        "    # Calculate policy gradient loss\n",
        "    rewards_tensor = torch.tensor(rewards, device=policy_logits.device).unsqueeze(-1)\n",
        "    pg_loss = -torch.mean(policy_log_probs_sampled * rewards_tensor * generated_mask)\n",
        "\n",
        "    # Final loss components\n",
        "    kl_loss = torch.mean(kl_div * generated_mask)\n",
        "    ent_loss = torch.mean(entropy)\n",
        "\n",
        "    total_loss = pg_loss + kl_coeff * kl_loss - entropy_coeff * ent_loss\n",
        "\n",
        "    return total_loss, (pg_loss.item(), kl_loss.item(), ent_loss.item())\n",
        "\n",
        "# ===== OPTIMIZED REFERENCE MODEL COMPUTATION =====\n",
        "def compute_reference_log_probs_memory_efficient(sampled_ids, prompt_length, chunk_size=5):\n",
        "    \"\"\"\n",
        "    Process reference model in chunks to avoid OOM\n",
        "    \"\"\"\n",
        "    generated_ids_only = sampled_ids[:, prompt_length:]\n",
        "    gen_length = generated_ids_only.shape[1]\n",
        "\n",
        "    # If no generated tokens, return empty tensor\n",
        "    if gen_length == 0:\n",
        "        return torch.empty((1, 0), device=sampled_ids.device)\n",
        "\n",
        "    ref_log_probs_chunks = []\n",
        "\n",
        "    for start_idx in range(0, gen_length, chunk_size):\n",
        "        end_idx = min(start_idx + chunk_size, gen_length)\n",
        "\n",
        "        chunk_ids = generated_ids_only[:, start_idx:end_idx]\n",
        "        chunk_mask = (chunk_ids != tokenizer.pad_token_id).long().to(chunk_ids.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            ref_outputs = reference_model(\n",
        "                input_ids=chunk_ids,\n",
        "                attention_mask=chunk_mask\n",
        "            )\n",
        "\n",
        "            # Use mixed precision carefully\n",
        "            with torch.amp.autocast('cuda', enabled=False):\n",
        "                chunk_logits = ref_outputs.logits.float()\n",
        "                chunk_log_probs = F.log_softmax(chunk_logits, dim=-1)\n",
        "\n",
        "            # Gather probabilities for actual tokens\n",
        "            chunk_sampled_probs = torch.gather(\n",
        "                chunk_log_probs, -1, chunk_ids.unsqueeze(-1)\n",
        "            ).squeeze(-1)\n",
        "\n",
        "            ref_log_probs_chunks.append(chunk_sampled_probs.cpu())\n",
        "\n",
        "        # Cleanup\n",
        "        del ref_outputs, chunk_logits, chunk_log_probs, chunk_sampled_probs\n",
        "        if start_idx % (chunk_size * 2) == 0:  # Clear memory periodically\n",
        "            clear_memory()\n",
        "\n",
        "    return torch.cat(ref_log_probs_chunks, dim=1)\n",
        "\n",
        "# ===== OPTIMIZED TRAINING LOOP =====\n",
        "model.train()\n",
        "global_step = 0\n",
        "\n",
        "print(\"\\nStarting memory-optimized training...\")\n",
        "print(f\"Config: batch_size={batch_size}, samples_per_prompt={samples_per_prompt}\")\n",
        "\n",
        "for step in range(num_steps):\n",
        "    print(f\"\\n--- Step {step + 1} / {num_steps} ---\")\n",
        "\n",
        "    # Sample data for this step\n",
        "    epoch_data = dataset.shuffle(seed=step)[:batch_size * accumulation_steps]\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    total_loss_accum = 0.0\n",
        "    avg_reward_accum = 0.0\n",
        "    all_pg_loss, all_kl_loss, all_ent_loss = 0.0, 0.0, 0.0\n",
        "\n",
        "    for accum_step in range(accumulation_steps):\n",
        "        print(f\"  Accumulation Step {accum_step + 1}/{accumulation_steps}\")\n",
        "\n",
        "        # --- Prepare Micro-Batch ---\n",
        "        start_idx = accum_step * batch_size\n",
        "        end_idx = (accum_step + 1) * batch_size\n",
        "        batch = {\n",
        "            \"prompt\": epoch_data[\"prompt\"][start_idx:end_idx],\n",
        "            \"ground_truth\": epoch_data[\"ground_truth\"][start_idx:end_idx]\n",
        "        }\n",
        "        prompts = batch[\"prompt\"]\n",
        "        ground_truths = batch[\"ground_truth\"]\n",
        "\n",
        "        # Tokenize (keep on CPU initially)\n",
        "        inputs = tokenizer(\n",
        "            prompts,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=max_prompt_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        prompt_length = inputs.input_ids.shape[1]\n",
        "\n",
        "        all_samples = []\n",
        "\n",
        "        # --- Rollout Phase - Process one prompt at a time ---\n",
        "        print(f\"    Generating {samples_per_prompt} samples per prompt...\")\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            prompt_input_ids = inputs.input_ids[i:i+1]\n",
        "            prompt_attention_mask = inputs.attention_mask[i:i+1]\n",
        "\n",
        "            # Move single prompt to GPU\n",
        "            prompt_input_ids = prompt_input_ids.to(device)\n",
        "            prompt_attention_mask = prompt_attention_mask.to(device)\n",
        "\n",
        "            for sample_idx in range(samples_per_prompt):\n",
        "                # Initialize variables\n",
        "                outputs = sampled_ids = ref_log_probs = None\n",
        "\n",
        "                try:\n",
        "                    with torch.no_grad():\n",
        "                        # Generate with lower precision if supported\n",
        "                        with torch.amp.autocast('cuda', dtype=torch.float16):\n",
        "                            outputs = model.generate(\n",
        "                                input_ids=prompt_input_ids,\n",
        "                                attention_mask=prompt_attention_mask,\n",
        "                                max_new_tokens=max_total_length - prompt_length,\n",
        "                                do_sample=True,\n",
        "                                temperature=rollout_temperature,\n",
        "                                top_p=1.0,\n",
        "                                pad_token_id=tokenizer.pad_token_id,\n",
        "                                return_dict_in_generate=True,\n",
        "                                output_scores=False,\n",
        "                                repetition_penalty=1.1,\n",
        "                            )\n",
        "\n",
        "                        sampled_ids = outputs.sequences\n",
        "\n",
        "                        # Compute reward (on CPU)\n",
        "                        decoded_response = tokenizer.decode(sampled_ids[0].cpu(), skip_special_tokens=True)\n",
        "                        reward = compute_reward(decoded_response, ground_truths[i])\n",
        "\n",
        "                        # Memory-efficient reference log probs\n",
        "                        ref_log_probs = compute_reference_log_probs_memory_efficient(\n",
        "                            sampled_ids, prompt_length, chunk_size=3\n",
        "                        )\n",
        "\n",
        "                        # Store sample data\n",
        "                        all_samples.append({\n",
        "                            'sampled_ids': sampled_ids.cpu(),\n",
        "                            'attention_mask': (sampled_ids != tokenizer.pad_token_id).long().cpu(),\n",
        "                            'ref_log_probs': ref_log_probs.cpu(),\n",
        "                            'reward': reward,\n",
        "                        })\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"    Error generating sample {sample_idx} for prompt {i}: {e}\")\n",
        "                    continue\n",
        "\n",
        "                finally:\n",
        "                    # Clean up\n",
        "                    variables_to_clean = ['outputs', 'sampled_ids', 'ref_log_probs']\n",
        "                    for var_name in variables_to_clean:\n",
        "                        if var_name in locals() and locals()[var_name] is not None:\n",
        "                            del locals()[var_name]\n",
        "\n",
        "                # Clear memory after each sample\n",
        "                if sample_idx % 2 == 0:\n",
        "                    clear_memory()\n",
        "\n",
        "            # Clear prompt-specific memory\n",
        "            del prompt_input_ids, prompt_attention_mask\n",
        "            clear_memory()\n",
        "\n",
        "        # --- Loss Calculation - Process samples sequentially ---\n",
        "        print(\"    Calculating loss...\")\n",
        "        if not all_samples:\n",
        "            print(\"    WARNING: No samples generated. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        total_samples = len(all_samples)\n",
        "        micro_batch_loss = 0.0\n",
        "        micro_batch_rewards = 0.0\n",
        "        micro_pg_loss, micro_kl_loss, micro_ent_loss = 0.0, 0.0, 0.0\n",
        "\n",
        "        for sample_idx, sample in enumerate(all_samples):\n",
        "            # Initialize variables to None\n",
        "            sampled_ids = attention_mask = ref_log_probs = policy_outputs = None\n",
        "            policy_logits = sample_loss = weighted_loss = None\n",
        "\n",
        "            try:\n",
        "                # Move only one sample to GPU at a time\n",
        "                sampled_ids = sample['sampled_ids'].to(device, non_blocking=True)\n",
        "                attention_mask = sample['attention_mask'].to(device, non_blocking=True)\n",
        "                ref_log_probs = sample['ref_log_probs'].to(device, dtype=torch.float16, non_blocking=True)\n",
        "                reward = sample['reward']\n",
        "\n",
        "                # Forward pass with mixed precision\n",
        "                with torch.amp.autocast('cuda', dtype=torch.float16):\n",
        "                    policy_outputs = model(\n",
        "                        input_ids=sampled_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        output_hidden_states=False,\n",
        "                        output_attentions=False\n",
        "                    )\n",
        "\n",
        "                    # Extract policy logits for generated tokens only\n",
        "                    policy_logits = policy_outputs.logits[:, prompt_length-1:-1, :]\n",
        "\n",
        "                    # Compute loss for single sample using safe function\n",
        "                    sample_loss, (sample_pg, sample_kl, sample_ent) = safe_compute_grpo_loss(\n",
        "                        policy_logits=policy_logits.unsqueeze(0),  # Add batch dim\n",
        "                        policy_sampled_ids=sampled_ids.unsqueeze(0),\n",
        "                        policy_attention_mask=attention_mask.unsqueeze(0),\n",
        "                        ref_log_probs_generated=ref_log_probs.unsqueeze(0),\n",
        "                        rewards=[reward],\n",
        "                        kl_coeff=kl_coeff,\n",
        "                        entropy_coeff=entropy_coeff,\n",
        "                        pad_token_id=tokenizer.pad_token_id,\n",
        "                        prompt_length=prompt_length\n",
        "                    )\n",
        "\n",
        "                    # Scale loss for accumulation\n",
        "                    weighted_loss = sample_loss / (total_samples * accumulation_steps)\n",
        "\n",
        "                # Backward pass\n",
        "                scaler.scale(weighted_loss).backward()\n",
        "\n",
        "                # Accumulate metrics\n",
        "                micro_batch_loss += weighted_loss.item()\n",
        "                micro_batch_rewards += reward\n",
        "                micro_pg_loss += sample_pg / total_samples\n",
        "                micro_kl_loss += sample_kl / total_samples\n",
        "                micro_ent_loss += sample_ent / total_samples\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e):\n",
        "                    print(f\"    OOM at sample {sample_idx}, skipping...\")\n",
        "                    clear_memory()\n",
        "                    continue\n",
        "                elif \"size of tensor\" in str(e):\n",
        "                    print(f\"    Tensor size mismatch at sample {sample_idx}: {e}\")\n",
        "                    print(f\"    Sample shapes - sampled_ids: {sample['sampled_ids'].shape}, ref_log_probs: {sample['ref_log_probs'].shape}\")\n",
        "                    clear_memory()\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f\"    Runtime error at sample {sample_idx}: {e}\")\n",
        "                    clear_memory()\n",
        "                    continue\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    Unexpected error at sample {sample_idx}: {e}\")\n",
        "                clear_memory()\n",
        "                continue\n",
        "\n",
        "            finally:\n",
        "                # Safe cleanup - only delete variables that were defined\n",
        "                variables_to_delete = ['sampled_ids', 'attention_mask', 'ref_log_probs',\n",
        "                                     'policy_outputs', 'policy_logits', 'sample_loss', 'weighted_loss']\n",
        "\n",
        "                for var_name in variables_to_delete:\n",
        "                    if var_name in locals() and locals()[var_name] is not None:\n",
        "                        del locals()[var_name]\n",
        "\n",
        "                if sample_idx % 2 == 0:\n",
        "                    clear_memory()\n",
        "\n",
        "        # Update accumulators\n",
        "        if total_samples > 0:\n",
        "            total_loss_accum += micro_batch_loss\n",
        "            avg_reward_accum += micro_batch_rewards / total_samples\n",
        "            all_pg_loss += micro_pg_loss / accumulation_steps\n",
        "            all_kl_loss += micro_kl_loss / accumulation_steps\n",
        "            all_ent_loss += micro_ent_loss / accumulation_steps\n",
        "\n",
        "            print(f\"    Micro-batch Loss: {micro_batch_loss:.4f} (PG: {micro_pg_loss:.4f}, KL: {micro_kl_loss:.4f}, Ent: {micro_ent_loss:.4f})\")\n",
        "            print(f\"    Avg Reward: {micro_batch_rewards / total_samples:.4f}\")\n",
        "\n",
        "        # Clean up micro-batch data\n",
        "        del all_samples, batch, inputs\n",
        "        clear_memory()\n",
        "\n",
        "    # --- Optimizer Step ---\n",
        "    print(f\"  Performing optimizer step...\")\n",
        "\n",
        "    # Gradient clipping\n",
        "    scaler.unscale_(optimizer)\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    global_step += 1\n",
        "\n",
        "    # --- Logging ---\n",
        "    print(f\"--- Step {step + 1} Completed ---\")\n",
        "    print(f\"  Total Loss: {total_loss_accum:.4f}\")\n",
        "    print(f\"  Avg Reward: {avg_reward_accum / accumulation_steps:.4f}\")\n",
        "    print(f\"  Components (PG: {all_pg_loss:.4f}, KL: {all_kl_loss:.4f}, Ent: {all_ent_loss:.4f})\")\n",
        "\n",
        "    # --- Checkpointing ---\n",
        "    if (step + 1) % 50 == 0:\n",
        "        print(f\"Saving checkpoint at step {step + 1}...\")\n",
        "        try:\n",
        "            # Save to CPU to free GPU memory\n",
        "            model_cpu = {k: v.cpu() for k, v in model.state_dict().items()}\n",
        "            checkpoint_path = f\"grpo_checkpoint_step_{step + 1}.pt\"\n",
        "            torch.save(model_cpu, checkpoint_path)\n",
        "            del model_cpu\n",
        "            print(f\"Checkpoint saved to {checkpoint_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving checkpoint: {e}\")\n",
        "        clear_memory()\n",
        "\n",
        "print(\"\\nTraining finished successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDUJqofxqwwg",
        "outputId": "bfa2ced8-bbc1-4c7d-e914-f0e2734479b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting memory-optimized training...\n",
            "Config: batch_size=4, samples_per_prompt=2\n",
            "\n",
            "--- Step 1 / 200 ---\n",
            "  Accumulation Step 1/8\n",
            "    Generating 2 samples per prompt...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "Caching is incompatible with gradient checkpointing in Qwen2DecoderLayer. Setting `past_key_values=None`.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Calculating loss...\n",
            "    Tensor size mismatch at sample 0: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 1: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 2: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 3: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 4: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 5: The size of tensor a (645) must match the size of tensor b (133) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 645]), ref_log_probs: torch.Size([1, 133])\n",
            "    Tensor size mismatch at sample 6: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 7: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Micro-batch Loss: 0.0000 (PG: 0.0000, KL: 0.0000, Ent: 0.0000)\n",
            "    Avg Reward: 0.0000\n",
            "  Accumulation Step 2/8\n",
            "    Generating 2 samples per prompt...\n",
            "    Calculating loss...\n",
            "    Tensor size mismatch at sample 0: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 1: The size of tensor a (540) must match the size of tensor b (28) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 540]), ref_log_probs: torch.Size([1, 28])\n",
            "    Tensor size mismatch at sample 2: The size of tensor a (727) must match the size of tensor b (215) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 727]), ref_log_probs: torch.Size([1, 215])\n",
            "    Tensor size mismatch at sample 3: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 4: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 5: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 6: The size of tensor a (627) must match the size of tensor b (115) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 627]), ref_log_probs: torch.Size([1, 115])\n",
            "    Tensor size mismatch at sample 7: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Micro-batch Loss: 0.0000 (PG: 0.0000, KL: 0.0000, Ent: 0.0000)\n",
            "    Avg Reward: 0.0000\n",
            "  Accumulation Step 3/8\n",
            "    Generating 2 samples per prompt...\n",
            "    Calculating loss...\n",
            "    Tensor size mismatch at sample 0: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 1: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 2: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 3: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 4: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 5: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 6: The size of tensor a (650) must match the size of tensor b (138) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 650]), ref_log_probs: torch.Size([1, 138])\n",
            "    Tensor size mismatch at sample 7: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Micro-batch Loss: 0.0000 (PG: 0.0000, KL: 0.0000, Ent: 0.0000)\n",
            "    Avg Reward: 0.0000\n",
            "  Accumulation Step 4/8\n",
            "    Generating 2 samples per prompt...\n",
            "    Calculating loss...\n",
            "    Tensor size mismatch at sample 0: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 1: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 2: The size of tensor a (634) must match the size of tensor b (122) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 634]), ref_log_probs: torch.Size([1, 122])\n",
            "    Tensor size mismatch at sample 3: The size of tensor a (688) must match the size of tensor b (176) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 688]), ref_log_probs: torch.Size([1, 176])\n",
            "    Tensor size mismatch at sample 4: The size of tensor a (659) must match the size of tensor b (147) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 659]), ref_log_probs: torch.Size([1, 147])\n",
            "    Tensor size mismatch at sample 5: The size of tensor a (613) must match the size of tensor b (101) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 613]), ref_log_probs: torch.Size([1, 101])\n",
            "    Tensor size mismatch at sample 6: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 7: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Micro-batch Loss: 0.0000 (PG: 0.0000, KL: 0.0000, Ent: 0.0000)\n",
            "    Avg Reward: 0.0000\n",
            "  Accumulation Step 5/8\n",
            "    Generating 2 samples per prompt...\n",
            "    Calculating loss...\n",
            "    Tensor size mismatch at sample 0: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 1: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 2: The size of tensor a (579) must match the size of tensor b (67) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 579]), ref_log_probs: torch.Size([1, 67])\n",
            "    Tensor size mismatch at sample 3: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 4: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 5: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 6: The size of tensor a (557) must match the size of tensor b (45) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 557]), ref_log_probs: torch.Size([1, 45])\n",
            "    Tensor size mismatch at sample 7: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Micro-batch Loss: 0.0000 (PG: 0.0000, KL: 0.0000, Ent: 0.0000)\n",
            "    Avg Reward: 0.0000\n",
            "  Accumulation Step 6/8\n",
            "    Generating 2 samples per prompt...\n",
            "    Calculating loss...\n",
            "    Tensor size mismatch at sample 0: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 1: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 2: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 3: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 4: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 5: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 6: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 7: The size of tensor a (525) must match the size of tensor b (13) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 525]), ref_log_probs: torch.Size([1, 13])\n",
            "    Micro-batch Loss: 0.0000 (PG: 0.0000, KL: 0.0000, Ent: 0.0000)\n",
            "    Avg Reward: 0.0000\n",
            "  Accumulation Step 7/8\n",
            "    Generating 2 samples per prompt...\n",
            "    Calculating loss...\n",
            "    Tensor size mismatch at sample 0: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 1: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 2: The size of tensor a (539) must match the size of tensor b (27) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 539]), ref_log_probs: torch.Size([1, 27])\n",
            "    Tensor size mismatch at sample 3: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 4: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 5: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 6: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 7: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Micro-batch Loss: 0.0000 (PG: 0.0000, KL: 0.0000, Ent: 0.0000)\n",
            "    Avg Reward: 0.0000\n",
            "  Accumulation Step 8/8\n",
            "    Generating 2 samples per prompt...\n",
            "    Calculating loss...\n",
            "    Tensor size mismatch at sample 0: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 1: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 2: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 3: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 4: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 5: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 6: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Tensor size mismatch at sample 7: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2\n",
            "    Sample shapes - sampled_ids: torch.Size([1, 768]), ref_log_probs: torch.Size([1, 256])\n",
            "    Micro-batch Loss: 0.0000 (PG: 0.0000, KL: 0.0000, Ent: 0.0000)\n",
            "    Avg Reward: 0.0000\n",
            "  Performing optimizer step...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Attempted unscale_ but _scale is None.  This may indicate your script did not use scaler.scale(loss or outputs) earlier in the iteration.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-684090589.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;31m# Gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36munscale_\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_scale_growth_tracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unscale_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0moptimizer_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_per_optimizer_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_check_scale_growth_tracker\u001b[0;34m(self, funcname)\u001b[0m\n\u001b[1;32m    160\u001b[0m     ) -> tuple[torch.Tensor, torch.Tensor]:\n\u001b[1;32m    161\u001b[0m         \u001b[0mfix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"This may indicate your script did not use scaler.scale(loss or outputs) earlier in the iteration.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         assert self._scale is not None, (\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0;34mf\"Attempted {funcname} but _scale is None.  \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         )\n",
            "\u001b[0;31mAssertionError\u001b[0m: Attempted unscale_ but _scale is None.  This may indicate your script did not use scaler.scale(loss or outputs) earlier in the iteration."
          ]
        }
      ]
    }
  ]
}